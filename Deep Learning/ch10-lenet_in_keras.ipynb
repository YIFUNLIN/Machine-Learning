{"cells":[{"cell_type":"markdown","metadata":{"id":"LCrpJ__5crC_"},"source":["# Ch10 機器視覺實戰演練：CNN (Convolutional Neural Network)"]},{"cell_type":"markdown","metadata":{"id":"v9zImDOecrDG"},"source":["#### 10.3.1 匯入模組"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2606,"status":"ok","timestamp":1629448755406,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"},"user_tz":-480},"id":"8tHsQTg3crDH"},"outputs":[],"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D # new!\n","                           # 將多軸轉成一軸   卷積層   最大池化層 "]},{"cell_type":"markdown","metadata":{"id":"JDG4iWaPcrDI"},"source":["#### 10.3.2 載入資料集並做資料預處理"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":714,"status":"ok","timestamp":1629448761129,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"},"user_tz":-480},"id":"bSUXg8VScrDI","outputId":"770758ef-cc8a-4b7e-ce39-7c829701f5a4"},"outputs":[],"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()  "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["訓練資料要傳遞給Conv2D()時，必須先轉成4軸陣列的形式，分別是(樣本數 * 寬 * 高 * 顏色通道)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":270,"status":"ok","timestamp":1629448769872,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"},"user_tz":-480},"id":"iRqUTGZOcrDK"},"outputs":[],"source":["X_train = X_train.reshape(60000, 28, 28, 1).astype('float32')  #(60000張手寫字,寬=28,高=28,由於MNIST數字為單色影像，所以設為1，若全採則設為3)\n","X_test = X_test.reshape(10000, 28, 28, 1).astype('float32')    # astype() 會將像素質從整數轉為浮點數"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["縮小X範圍"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1629448772123,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"},"user_tz":-480},"id":"0yXPh5DWcrDK"},"outputs":[],"source":["X_train /= 255    \n","X_test /= 255"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["將標籤y轉換為one-hot encoding"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1629448775071,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"},"user_tz":-480},"id":"lpvOXbakcrDL"},"outputs":[],"source":["n_classes = 10\n","y_train = to_categorical(y_train, n_classes)\n","y_test = to_categorical(y_test, n_classes)"]},{"cell_type":"markdown","metadata":{"id":"3rJlLunYcrDL"},"source":["#### 10.3.3 規劃 CNN 模型的架構"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":682,"status":"ok","timestamp":1629448785766,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"},"user_tz":-480},"id":"EgcJ4UDTcrDL"},"outputs":[],"source":["model = Sequential()\n","\n","#第一層隱藏層\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n","#    卷積層的濾鏡數=32個  濾鏡尺寸=3*3的眷積核   激活函數用Relu  輸入影像為28*28會得到26*26的特徵圖、步長為1 \n","\n","#第二層隱藏層\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))  #濾鏡數為64\n","model.add(MaxPooling2D(pool_size=(2, 2)))    #加入 最大池化層 用來繼續減少特徵圖的尺寸 滑動窗口尺寸=2*2，步長預設為2\n","model.add(Dropout(0.25))   #降低模型overfitting\n","model.add(Flatten())   #會把MaxPooling輸出的特徵圖展平為1D陣列，這樣才能把這些像素值傳給\"密集層\"(只接受1D作為輸入)\n","\n","#搭配丟棄法的密集隱藏層\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","#輸出層\n","model.add(Dense(n_classes, activation='softmax'))   #利用softmax換成各類別的機率"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1629448788816,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"},"user_tz":-480},"id":"tcDNogB-crDM","outputId":"378d20fe-13f9-490e-cc23-ccc2a4e1d7c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 24, 24, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 12, 12, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_2 (Dropout)         (None, 12, 12, 64)        0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 9216)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               1179776   \n","                                                                 \n"," dropout_3 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 1,199,882\n","Trainable params: 1,199,882\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"nshunun8crDM"},"source":["#### 10.3.4 編譯、訓練模型"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":394,"status":"ok","timestamp":1629448803570,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"},"user_tz":-480},"id":"bYtYnJ1gcrDM"},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1212355,"status":"ok","timestamp":1629450028000,"user":{"displayName":"Tristan Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh12xA8ZXwa1dgzXFsLj_MwkqJdmxu_hK6DdwmvTQ=s64","userId":"01396821554749831700"},"user_tz":-480},"id":"XFo1S4LecrDN","outputId":"966bf0f4-e04e-4dac-c8b4-22c3fcd5c88d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","469/469 [==============================] - 46s 97ms/step - loss: 1.0465 - accuracy: 0.6525 - val_loss: 0.3234 - val_accuracy: 0.9057\n","Epoch 2/10\n","469/469 [==============================] - 46s 97ms/step - loss: 0.4686 - accuracy: 0.8562 - val_loss: 0.2414 - val_accuracy: 0.9276\n","Epoch 3/10\n","226/469 [=============>................] - ETA: 22s - loss: 0.4209 - accuracy: 0.8715"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#註：由於神經網路的初始權重參數是隨機設定的, 參雜了隨機性, 因此底下 (或您重跑一次) 的結果不會與書中完全一樣, 但模型的能力是相近的\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#註：由於神經網路的初始權重參數是隨機設定的, 參雜了隨機性, 因此底下 (或您重跑一次) 的結果不會與書中完全一樣, 但模型的能力是相近的\n","model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(X_test, y_test))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ch10-lenet_in_keras.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
